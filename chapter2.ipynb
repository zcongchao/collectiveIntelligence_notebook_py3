{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 集体智慧编程第二章：推荐算法——协同过滤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 什么是推荐？\n",
    "推荐，就是根据个人偏好，对某个人进行个性化推荐。\n",
    "\n",
    "在线购物的商品推荐\n",
    "热门网站的推荐\n",
    "音乐推荐\n",
    "电影、电视的推荐\n",
    "推荐的依据主要来自每个人过去的操作：购买、评分、评论。对这些过去的数据利用算法进行处理，就能得到这个人的偏好、甚至产生值得推荐的产品。\n",
    "通常，我们会询问朋友有什么好看的电影，当然正常人都会询问和自己有着相同爱好的人。那么有一种算法叫做协同过滤：就是找到和目标用户有着相同爱好的人，然推荐给目标用户，这些有相同爱好的人喜欢的物品。本文主要就是讲这个算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 推荐电影的例子\n",
    "\n",
    "下面，我们通过一个实际的小例子来完成这个过程，这个例子是关于用户电影的。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用户的历史操作\n",
    "\n",
    "完成协同过滤这个算法的第一步就是你要知道谁喜欢什么。本例子中，不仅知道哪个用户喜欢哪个电影，并且还用具体的数字来量化了，也就是每人对电影的有着评分。用一个字典表示，具体代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#一个字典，第一个key是人名，value是又是一个字典，字典里面是key电影名，value是评分   \n",
    "critics={'Lisa Rose': {'Lady in the Water': 2.5, 'Snakes on a Plane': 3.5,\n",
    " 'Just My Luck': 3.0, 'Superman Returns': 3.5, 'You, Me and Dupree': 2.5, \n",
    " 'The Night Listener': 3.0},\n",
    "'Gene Seymour': {'Lady in the Water': 3.0, 'Snakes on a Plane': 3.5, \n",
    " 'Just My Luck': 1.5, 'Superman Returns': 5.0, 'The Night Listener': 3.0, \n",
    " 'You, Me and Dupree': 3.5}, \n",
    "'Michael Phillips': {'Lady in the Water': 2.5, 'Snakes on a Plane': 3.0,\n",
    " 'Superman Returns': 3.5, 'The Night Listener': 4.0},\n",
    "'Claudia Puig': {'Snakes on a Plane': 3.5, 'Just My Luck': 3.0,\n",
    " 'The Night Listener': 4.5, 'Superman Returns': 4.0, \n",
    " 'You, Me and Dupree': 2.5},\n",
    "'Mick LaSalle': {'Lady in the Water': 3.0, 'Snakes on a Plane': 4.0, \n",
    " 'Just My Luck': 2.0, 'Superman Returns': 3.0, 'The Night Listener': 3.0,\n",
    " 'You, Me and Dupree': 2.0}, \n",
    "'Jack Matthews': {'Lady in the Water': 3.0, 'Snakes on a Plane': 4.0,\n",
    " 'The Night Listener': 3.0, 'Superman Returns': 5.0, 'You, Me and Dupree': 3.5},\n",
    "'Toby': {'Snakes on a Plane':4.5,'You, Me and Dupree':1.0,'Superman Returns':4.0}}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于用户的协同过滤\n",
    "协同过滤：就是找到和目标用户有着相同爱好的人，然推荐给目标用户，这些有相同爱好的人喜欢的物品。本文主要就是讲这个算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 计算用户相似度\n",
    "\n",
    "那么现在我们已经有了用户数据了，下一步就是：找出爱好相同的用户。专业术语：寻找相近用户或者相似度高的用户。下面介绍三种计算相似度的体系：\n",
    "\n",
    "欧几里得距离     \n",
    "皮尔逊相关度   \n",
    "Tanimoto系数   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 欧几里得距离\n",
    "\n",
    "\n",
    "首先是欧几里得距离：\n",
    "实际上，欧几里得距离非常直观，对于某两部电影，所有的用户都对其有着评分，我们以一个电影为x轴、一个电影为y轴，将每个人的对两个电影的评分画在坐标系中，直接考察每对用户的直线距离，距离近的相似度高。比如电影：dupree和snake，可以画出的图如下所示：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./zuobiao.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然这幅图只使用了二维坐标系，但实际上三维、四维都是同样的道理。\n",
    "求两点间直线的距离，我相信大家都知道怎么算吧？三维、四维、n维的其实和二维的一个道理，都是两点差的平方和，再开方。注意：两点是指两个用户。在二维中就有x，y轴两个差值的平方和，而在n维中，就是n个差值的平方和。在本题中，对于两用户，必须是共同评过分的电影才有计算的意义。求出平方和再开方就是直线距离了。现在两用户越相邻距离越小，但是我们希望得到的是用户越相邻，数值越大，（0-1之间），故我们对最后的结果加1再求倒数就可以了。试想：如果两点重合，距离为1，再求倒数则是0被除，所以必须要加一。而如果两点距离越远，求倒数后值越小，符合我们的要求。解释清楚之后，让我们来看一看代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#利用欧几里得计算两个人之间的相似度\n",
    "from math import sqrt\n",
    "\n",
    "def sim_distance(prefs, person1, person2):\n",
    "    #首先把这个两个用户共同拥有评过分电影给找出来，方法是建立一个字典，字典的key电影名字，电影的值就是1\n",
    "    si = {}\n",
    "    for item in prefs[person1]:\n",
    "        if item in prefs[person2]:\n",
    "            si[item]=1\n",
    "    #如果为空没有共同之处\n",
    "    if len(si)==0:\n",
    "        return 0\n",
    "    \n",
    "    #计算所有差值的平方和\n",
    "    sum_of_squares = sum([pow(prefs[person1][item] - prefs[person2][item], 2)\n",
    "                         for item in si ]) \n",
    "    \n",
    "    #用户越相邻，数值越大\n",
    "    return 1/(1+sqrt(sum_of_squares))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38742588672279304\n"
     ]
    }
   ],
   "source": [
    "print(sim_distance(critics,'Lisa Rose','Claudia Puig'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 皮尔逊相关度评价\n",
    "\n",
    "下面介绍的是皮尔逊相关度评价。用图里讲是非常清晰的，我们用某两个用户作为x、y轴，然后以用户对电影的评分，画出每一点来。如下图所示："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pearson_zuobiao.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图中superman电影的坐标为（3.0,5.0），这是因为用户Gene Seymour对其的评分为5，而mick lasalle的评分为3.考虑所有的点：我们画一条线，叫最佳拟合线：画的原则是尽可能地靠近图中所有的坐标点。就是上图的线，试想一种情况就是两个用户的评分完成一样，我们将得到一条线：所有点都在线上，而且线的角度是45度。这时，两个用户的兴趣完全相同，我们称之为1，我想别的拟合线与之对比即可看出差距吧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述这么多有点讲出了推导原理的感觉，我们但是实际上我们求的就是皮尔逊相关系数，这是一个数学上的公式,其最后得到的结果是一个-1到1的之间的小数。-1称之为负相关：表示一个变量的值越大，另一个变量的值会反而越来越小。计算过程首先要找出两位评论者曾经评价过的物品，然后计算两者的评分总和平方和，并求出评分的乘积之和。利用公式算出pearson相关系数，\n",
    "公式如下：其中X和Y分别是个数相同的数组或者是列表（python），相当于算出了两个数组之间的perason相关度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./pearson_gongshi.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#返回两个人的皮尔逊相关系数\n",
    "def sim_pearson(prefs,p1,p2):\n",
    " \n",
    " \n",
    "    si={}\n",
    "    for item in prefs[p1]:\n",
    "        if item in prefs[p2]: si[item]=1\n",
    " \n",
    " \n",
    "    #得到列表元素的个数\n",
    "    n=len(si)\n",
    " \n",
    " \n",
    "    #如果两者没有共同之处，则返回0\n",
    "    if n==0:return 1\n",
    "    \n",
    "    #对共同拥有的物品的评分，分别求和\n",
    "    sum1 = sum([prefs[p1][it] for it in si])\n",
    "    sum2 = sum([prefs[p2][it] for it in si])\n",
    "    \n",
    "    #求平方和\n",
    "    sum1sq = sum([pow(prefs[p1][it], 2) for it in si])\n",
    "    sum2sq = sum([pow(prefs[p2][it], 2) for it in si])\n",
    "    \n",
    "    #求乘积之和\n",
    "    psum = sum([prefs[p1][it]*prefs[p2][it] for it in si])\n",
    "    \n",
    "    #计算皮尔逊评价值\n",
    "    num = psum-(sum1*sum2/n)\n",
    "    den = sqrt((sum1sq-pow(sum1,2)/n)*(sum2sq-pow(sum2,2)/n))\n",
    "    \n",
    "    if den == 0:\n",
    "        return 0\n",
    "    \n",
    "    r = num/den\n",
    "    \n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39605901719066977\n"
     ]
    }
   ],
   "source": [
    "print(sim_pearson(critics, 'Lisa Rose', 'Gene Seymour'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "虽然两者都可以计算出相关度，哪个更好取决于实际的应用。但是pearson有一个明显非常不错的地方，它可以忽略掉一种情况：比如A用户每次给出的分都比B用户高，也就是说A给的分普遍较高，那么此时如果用欧几里得距离的算法的话，会判定A与B的相似度比较低。然而pearson算法可以修正这一点，依然会得出A与B的相似度较高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 找出相似用户\n",
    "\n",
    "既然可以计算每一对用户的相似度了，那么可以找出针对某一目标用户，与其兴趣相似的用户了。其实做的事就是做个循环，然后排个序，然后反转一下。代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def topMatches(prefs, person, n=5, similarity=sim_pearson):\n",
    "    scores = [(similarity(prefs, person, other), other) \n",
    "              for other in prefs if other != person]\n",
    "    scores.sort()\n",
    "    scores.reverse()\n",
    "    return scores[0:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.9912407071619299, 'Lisa Rose'), (0.9244734516419049, 'Mick LaSalle'), (0.8934051474415647, 'Claudia Puig')]\n"
     ]
    }
   ],
   "source": [
    "print(topMatches(critics, 'Toby', n=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 产生推荐列表\n",
    " \n",
    "\n",
    "我们确实可以得到与Toby兴趣相似的用户，然而，这并不是我们的最终目的，我们需要得到的是Toby可能喜欢的物品。根据书中的做法，如果从其相似用户中找随便挑一个没看过的电影做一个推荐的话，这太随意了。这一点非常重要，我现在觉得我音乐网站推荐系统也不能如此随意，但是我记得我后来将会该为基于物品的协同过滤，与此处的不同。先继续完成我的例子。\n",
    "为了杜绝这样的随意，我们会采用一种利用加权的方式来为目标用户没有看过的电影的预测打分。加权的意思是指：无论与目标用户的相似度低还是高，都会影响着我们预测目标用户没看过的电影的分数，只是权重不一样而已。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='./pingfen.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后一排中的红线3.35即是为Toby没看过的电影Night的预测得分。具体来的就是上两排的12.89处于3.84。12.89的来历是将所有看过该电影的用户的打分乘以与toby的相似度的和。而3.84仅仅就是所有相似用户的相似度的总和。我们可以看到对于电影Lady，由于puig没有看过，所以它会对预测toby的分有任何影响。这就是说：相似度越高的用户的评分越能影响着预测目标用户对某个电影的打分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getRecommendations(prefs, person, similarity=sim_pearson):\n",
    "    totals = {}\n",
    "    simsums = {}\n",
    "    for other in prefs:\n",
    "        #不用和自己比较了\n",
    "        if other == person:\n",
    "            continue\n",
    "        sim = similarity(prefs, person, other)\n",
    "        #print(sim)\n",
    "            ##忽略相似度为0或者是小于0的情况\n",
    "        if sim <= 0:\n",
    "            continue\n",
    "        for item in prefs[other]:\n",
    "            #只对自己还没看过的电影进行评价\n",
    "            if item not in prefs[person] or prefs[person][item] == 0:\n",
    "                #相似度*评价值。setdefault就是如果没有就新建，如果有，就取那个item\n",
    "                totals.setdefault(item, 0)\n",
    "                totals[item] += prefs[other][item]*sim\n",
    "\n",
    "                #相似度之和\n",
    "                simsums.setdefault(item, 0)\n",
    "                simsums[item] += sim\n",
    "    #print(totals)\n",
    "    #建立一个归一化的列表\n",
    "    rankings = [ (total/simsums[item], item) for item, total in totals.items() ]\n",
    "    \n",
    "    #返回好经过排序的列表\n",
    "    rankings.sort()\n",
    "    rankings.reverse()\n",
    "    return rankings                    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3.3477895267131013, 'The Night Listener'), (2.8325499182641614, 'Lady in the Water'), (2.530980703765565, 'Just My Luck')]\n"
     ]
    }
   ],
   "source": [
    "print(getRecommendations(critics, 'Toby'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于物品的协同过滤\n",
    "数据的转变\n",
    "\n",
    "接下来要将一个重要的思想。就是根据利用用户对电影的评分，求出电影之间的相似度。\n",
    "\n",
    "试想，刚刚我们在topMatches方法里面得到了什么？与用户兴趣相似的用户。现在我们要求的是与电影相似的电影。这只是需要一个思维的转变。\n",
    "那就是：将用户对电影的评分看成，电影对用户的适应度。大概就是这个意思：大概电影自己给用户打了一个分：就是电影适合用户的程度。比如电影A给用户x打了4分，电影A又给用户y打了3分，结果电影B给用户x打了4分，电影B又给用户y打了3分。好吧，我们现在就说这个电影A和电影B相似度百分百。因为它们两个对用户的适应度一模一样。\n",
    "准备工作就是首先把字典里面的用户与电影的对应关系换一下。    \n",
    "转变前："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Lisa Rose': {'Lady in the Water': 2.5, 'Snakes on a Plane': 3.5,'Just My Luck': 3.0, 'Superman Returns': 3.5, 'You, Me and Dupree': 2.5,  'The Night Listener': 3.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转变后："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Lady in the Water': {'Lisa Rose': 2.5, 'Jack Matthews': 3.0, 'Michael Phillips': 2.5, 'Gene Seymour': 3.0, 'Mick LaSalle': 3.0}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#将用户对电影的评分改为，电影对用户的适应度\n",
    "def transformprefs(prefs):\n",
    "    result = {}\n",
    "    for person in prefs:\n",
    "        for item in prefs[person]:\n",
    "            result.setdefault(item, {})\n",
    "            #将物品和人员对调\n",
    "            result[item][person] = prefs[person][item] \n",
    "            \n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.6579516949597695, 'You, Me and Dupree'), (0.4879500364742689, 'Lady in the Water'), (0.11180339887498941, 'Snakes on a Plane'), (-0.1798471947990544, 'The Night Listener'), (-0.42289003161103106, 'Just My Luck')]\n"
     ]
    }
   ],
   "source": [
    "#得到与'Superman Returns'相似度较高的电影\n",
    "print(topMatches(transformprefs(critics), 'Superman Returns'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基于用户、基于物品的选择\n",
    "\n",
    "最后分析一下对于基于用户的协同过滤和基于物品的协同过滤的选择问题。\n",
    "首先书中提到了两点：\n",
    "生成推荐列表时，基于物品的方式比基于用户的方式速度更快\n",
    "维护物品相似度表有着额外的开销\n",
    "\n",
    "接着，在准确率上，又提出两点：\n",
    "\n",
    "对于稀疏数据集，基于物品的方式要优于基于用户的方式\n",
    "对于密集数据集，两者效果几乎一样\n",
    "关于是什么是密集什么是稀疏，我现在的理解就是。电影与评论电影的人相比，明显电影少，人多，所以每个用户都几乎对每一个电影做了评价，这就是密集型的。而书签多，用户少，大部分书签都被少量用户收集，这就是稀疏。这里的结论我觉得很重要。\n",
    "\n",
    "到此，整个推荐的学习，我觉得足够了，而且非常充实。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
